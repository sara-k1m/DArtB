# 용어 정리

## 6.1 
- **이웃**: 예측변수에서 값들이 유사한 레코드  
- **거리 지표**: 각 레코드 사이가 얼마나 멀리 떨어져 있는지를 나타내는 단일 값  
- **표준화**: 평균을 뺀 후에 표준편차로 나누는 일 (유의어: 정규화)  
- **z 점수**: 표준화를 통해 얻은 값  
- **k**: 최근접 이웃을 계산하는 데 사용되는 이웃의 개수  

## 6.2 
- **재귀 분할**: 마지막 분할 영역에 해당하는 출력이 최대한 비슷한 결과를 보이도록 데이터를 반복적으로 분할하는 것  
- **분할값**: 분할값을 기준으로 예측변수를 그 값보다 작은 영역과 큰 영역으로 나눔  
- **마디 (노드)**: 의사 결정 트리와 같은 가지치기 형태로 구성된 규칙들의 집합에서, 노드는 분할 규칙의 시각적인 표시  
- **잎**: if-then 규칙의 가장 마지막 부분, 혹은 트리의 마지막 가지 부분을 의미. 트리 모델에서 잎 노드는 어떤 레코드에 적용할 최종적인 분류 규칙  
- **손실**: 분류하는 과정에서 발생하는 오분류의 수. 손실이 클수록 불순도가 높음  
- **불순도**: 데이터를 분할한 집합에서 서로 다른 클래스의 데이터가 얼마나 섞여 있는지를 나타냄. 더 많이 섞여 있을수록 불순도가 높음 (유의어: 이질성, 반의어: 동질성, 순도)  
- **가지치기**: 학습이 끝난 트리 모델에서 오버피팅을 줄이기 위해 가지들을 하나씩 잘라내는 과정  

## 6.3 
- **앙상블**: 여러 모델의 집합을 이용해서 하나의 예측을 이끌어내는 방식 (유의어: 모델 평균화)  
- **배깅**: 데이터를 부트스트래핑해서 여러 모델을 만드는 일반적인 방법 (유의어: 부트스트랩 종합)  
- **랜덤 포레스트**: 의사 결정 트리 모델에 기반을 둔 배깅 추정 모델 (유의어: 배깅 의사 결정 트리)  
- **변수 중요도**: 모델 성능에 미치는 예측변수의 중요도  

## 6.4 
- **부스팅**: 연속된 라운드마다 잔차가 큰 레코드들에 가중치를 높여 일련의 모델들을 생성하는 일반 기법  
- **에이다부스트**: 잔차에 따라 데이터의 가중치를 조절하는 부스팅의 초기 버전  
- **그레이디언트 부스팅**: 비용함수를 최소화하는 방향으로 부스팅을 활용하는 좀 더 일반적인 형태  
- **확률적 그레이디언트 부스팅**: 각 라운드마다 레코드와 열을 재표본추출하는 것을 포함하는 부스팅의 가장 일반적인 형태  
- **정규화**: 비용함수에 모델의 파라미터 개수에 해당하는 벌점 항을 추가해 오버피팅을 피하는 방법  
- **하이퍼파라미터**: 알고리즘을 피팅하기 전에 미리 세팅해야 하는 파라미터  
